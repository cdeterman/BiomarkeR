% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/prediction.metrics.R
\name{prediction.metrics}
\alias{prediction.metrics}
\title{Prediction Metric Calculations}
\usage{
prediction.metrics(finalModel, method, raw.data, inTrain, outTrain, features,
  bestTune, grp.levs)
}
\arguments{
\item{finalModel}{List of fitted models}

\item{method}{Vector of strings dictating the models that were fit}

\item{raw.data}{Original dataset prior to any training subset}

\item{inTrain}{List of training indicies for each feature selection run}

\item{outTrain}{List of testing data indicies for each feature selection run}

\item{features}{List of selected features for each model}

\item{bestTune}{List of parameters that have been optimized for the each
respective model}

\item{grp.levs}{Vector of group levels}
}
\value{
Returns a dataframe consisting of each feature selection runs
evaluated Accuracy, Kappa, ROC.AUC, Sensitivity, Specificity, Positive
Predictive Value, and Negative Predictive Value.
}
\description{
Performance evaluation of all fitted models.  This function
concisely provides model performance metrics, including confusion matrix
and ROC.
}
\seealso{
\code{\link{performance.stats}},
\code{\link{perf.calc}} caret function \link[caret]{confusionMatrix}
}

